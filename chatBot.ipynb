{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divye/Desktop/meakuchatbot_project/meaku/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.holoviz.org/panel/1.4.5/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='c4c59b53-b59a-4571-959d-b0c77438da12'>\n",
       "  <div id=\"ed3669c0-32dc-4677-9552-172c9630fe97\" data-root-id=\"c4c59b53-b59a-4571-959d-b0c77438da12\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"2f585890-b723-480b-a149-d571c68c9a27\":{\"version\":\"3.4.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"c4c59b53-b59a-4571-959d-b0c77438da12\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"76b669fb-8a03-4f0b-84c4-9eb687b0cf98\",\"attributes\":{\"plot_id\":\"c4c59b53-b59a-4571-959d-b0c77438da12\",\"comm_id\":\"f609bdd14f7c42b18e1f3b2d18a049c8\",\"client_comm_id\":\"277e377c66f1437da572ba0795c38ed2\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"2f585890-b723-480b-a149-d571c68c9a27\",\"roots\":{\"c4c59b53-b59a-4571-959d-b0c77438da12\":\"ed3669c0-32dc-4677-9552-172c9630fe97\"},\"root_ids\":[\"c4c59b53-b59a-4571-959d-b0c77438da12\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "c4c59b53-b59a-4571-959d-b0c77438da12"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import panel as pn\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "CHROMA_PATH = \"input_data/chroma\"\n",
    "DATA_PATH = \"input_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divye/Desktop/meakuchatbot_project/meaku/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/divye/Desktop/meakuchatbot_project/meaku/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/divye/Desktop/meakuchatbot_project/meaku/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackerEarth is an online technical-recruitment tool that provides a wide range of benefits to users who use it regularly.\n",
      "\n",
      "1. Industry-Leading Features: HackerEarth offers industry-leading features that make it easy for organizations to recruit top talent quickly and efficiently. Some of the key features offered by HackerEarth include:\n",
      "\n",
      "- Automated Recruitment Process: HackerEarth offers an automated recruitment process that helps organizations streamline their recruitment processes and find top talent more efficiently. This process uses a variety of tools and technologies, including artificial intelligence, machine learning, natural language processing (NLP), and other advanced technology solutions, to automate the recruitment process and help organizations find top talent more efficiently.\n",
      "- Comprehensive Test Platform: HackerEarth offers a comprehensive test platform that enables organizations to create high-quality online technical assessments (TAs) that can help candidates prepare for interviews by providing them with the relevant knowledge and skills necessary to perform well in an interview setting. This test platform includes various components and functionalities, including:\n",
      "\n",
      "  1. Comprehensive Test Platform: The test platform is a comprehensive platform that enables organizations to create high-quality online technical assessments (TAs) that can help candidates prepare for interviews by providing them with the relevant knowledge and skills necessary to perform well in an interview setting.\n",
      "  2. Automated Questionnaire System: The questionnaire system is an automated questionnaires system that enables organizations to create high-quality online technical assessments (TAs) that can help candidates prepare for interviews by providing them with the relevant knowledge and skills necessary to perform well in an interview setting.\n",
      "  3. AI-Powered Assessment Scoring System: The assessment scoring system is an ai-powered assessment scoring system that enables organizations to create high-quality online technical assessments (TAs) that can help candidates prepare for interviews by providing them with the relevant knowledge and skills necessary to perform well in an interview setting.\n",
      "  4. Video Interview Platform: The video interview platform is a video interview platform that enables organizations to create high-quality online technical assessments (TAs) that can help candidates prepare for interviews by providing them with the relevant knowledge and skills necessary to perform well in an interview setting.\n",
      "  5. AI-Powered Chatbot Platform: The ai-powered chatbot platform is an ai-powered chatbot platform that enables organizations to create high-quality online technical assessments (TAs) that can help candidates prepare for interviews by providing them with the relevant knowledge and skills necessary to perform well in an interview setting.\n",
      "\n",
      "These are some of the key advantages provided by HackerEarth for organizations looking to automate their recruitment processes, identify top talent more efficiently, and ultimately make informed hiring decisions.\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)\n",
    "\n",
    "llm = ChatOllama(model=\"qwen:1.8b\", temperature=0)\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm, retriever=db.as_retriever())\n",
    "\n",
    "question = \"What are the advantages of using HackerEarth?\"\n",
    "result = chain.invoke({\"query\": question})\n",
    "\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "panel.chat.interface.ChatInterface"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "\n",
    "def generate_response(contents: str, user: str, chat_interface: pn.chat.ChatInterface):\n",
    "    chat_history = chat_interface.serialize(\n",
    "        format=\"transformers\",\n",
    "    )\n",
    "    response = ollama.chat(model=chain, stream=True, messages=chat_history)\n",
    "    message = \"\"\n",
    "    for partial_resp in response:\n",
    "        token = partial_resp[\"message\"][\"content\"]\n",
    "        message += token\n",
    "        yield message\n",
    "\n",
    "\n",
    "chat_interface = pn.chat.ChatInterface(callback=generate_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_interface.send(\n",
    "    \"Hi! How can i help you?\", user=\"System\", avatar=\"ðŸ¤–\", respond=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = pn.Column(\n",
    "    pn.pane.Markdown(\"# Qwen:1.8b Chatbot\"),\n",
    "    chat_interface,\n",
    "    styles={\n",
    "        \"padding\": \"15px\",\n",
    "        \"border\": \"1px solid white\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/divye/Desktop/meakuchatbot_project/meaku/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2024-08-11 23:43:30,501 Starting Bokeh server version 3.4.3 (running on Tornado 6.4.1)\n",
      "2024-08-11 23:43:30,504 User authentication hooks NOT provided (default user enabled)\n",
      "2024-08-11 23:43:30,506 Bokeh app running at: http://localhost:5006/\n",
      "2024-08-11 23:43:30,506 Starting Bokeh server with process id: 24677\n",
      "2024-08-11 23:43:31,815 WebSocket connection opened\n",
      "2024-08-11 23:43:31,817 ServerConnection created\n",
      "2024-08-11 23:43:42,047 WebSocket connection closed: code=1001, reason=None\n",
      "2024-08-11 23:43:42,163 WebSocket connection opened\n",
      "2024-08-11 23:43:42,164 ServerConnection created\n",
      "^C\n",
      "\n",
      "Interrupted, shutting down\n"
     ]
    }
   ],
   "source": [
    "chatbot.servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"qwen:1.8b\", temperature=0)\n",
    "\n",
    "RAG_PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "Do not repeat any information and be precise in your response.\n",
    "\"\"\"\n",
    "\n",
    "meaku_message = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistance for HackerEarth company. \\\n",
    "You first greet the customer in one line then collect their details such as name, email, contact number. \\\n",
    "You wait for the customer to respond then respond using the following context. \\\n",
    "{context_text} \\\n",
    "Answer the question using above context and donot repeat anything. \\\n",
    "You job is to engage customer asking about what are they looking for on the website so ask questions after responding. \\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "The company is about provide Human Resource services to their customers, the services include \\\n",
    "1. Repository of pre-built questions \\\n",
    "2. Assess a large pool of candidates in 38 different programming languages \\\n",
    "3. Versatile platform \\\n",
    "4. Advanced proctoring settings for assessments \\\n",
    "5. Detailed reports and analytics \\\n",
    "6. Dedicated account manager and product specialist available 24/7 \\\n",
    "7. Evaluates tests automatically to shortlist the best candidates \\\n",
    "If they are not looking for anything specific, you provide them details about what the company does and how its products can benefit the customer, \\\n",
    "             \",\n",
    "    ),\n",
    "    (\"human\", \"{input_text}\"),\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(meaku_message)\n",
    "\n",
    "\n",
    "def get_context(query_text):\n",
    "    embedding_function = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    return context_text\n",
    "\n",
    "\n",
    "def get_completion_from_messages(prompt, input_text, model=llm):\n",
    "    context_text = get_context(input_text)\n",
    "    chain = prompt | model\n",
    "    response_text = chain.invoke(\n",
    "        {\"context_text\": context_text, \"input_text\": input_text}\n",
    "    )\n",
    "    # response = openai.ChatCompletion.create(\n",
    "    #     model=model,\n",
    "    #     messages=messages,\n",
    "    #     temperature=0, # this is the degree of randomness of the model's output\n",
    "    # )\n",
    "    return response_text.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually testing the chat bot with three input texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divye/Desktop/MeakuChatBot/meaku/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/divye/Desktop/MeakuChatBot/meaku/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/divye/Desktop/MeakuChatBot/meaku/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackerEarth Assessment is designed to help you assess a large pool of candidates in a concise span of time. This means that you can quickly filter through a high volume of resumes and identify the best fit for your team. With HackerEarth Assessment, you can increase the number of candidates you assess, which can help you find the perfect candidate for your organization. This is particularly useful when you have multiple positions to fill or when you are looking to scale your team quickly. By automating the recruitment process, HackerEarth Assessment saves you time and effort and enables you to assess more candidates efficiently. This not only helps you find the right candidate faster but also ensures that you don't miss out on any potential hires.\n",
      "\n",
      "3. Diverse platform\n",
      "\n",
      "---\n",
      "\n",
      "6. Dedicated account manager and product specialist available 24/7\n",
      "\n",
      "HackerEarth Assessment offers exceptional service for its assessments, with a dedicated account manager and product specialist available 24/7 to assist with any technical issues. This guarantees a smooth and hassle-free experience while utilizing the platform to find the ideal candidate for your team.\n",
      "\n",
      "To know more about how HackerEarth Assessment helped organizations in hiring effectively, click here.\n",
      "\n",
      "What are the advantages of using HackerEarth Assessment?\n",
      "\n",
      "There are various advantages of using HackerEarth assessments which are as follows:\n",
      "\n",
      "Enables remote recruitment drives across multiple locations for seamless scaling\n",
      "\n",
      "---\n",
      "\n",
      "Overview\n",
      "\n",
      "HackerEarth is an online technical-recruitment tool that enables you to automate your hiring process to select the best fit for your team.\n",
      "\n",
      "Using HackerEarth Assessment, you can create tests to evaluate candidates. By automating your recruitment process, HackerEarth Assessment saves the time and effort required to go through hundreds of resumes manually. It allows you to assess and shortlist a targeted pool of candidates who suit your requirements.\n",
      "\n",
      "This article gives you an in-depth understanding of HackerEarth Assessment and its benefits. By using HackerEarth, you can streamline the recruitment process and find the perfect candidate for your team.\n",
      "\n",
      "Why should you use HackerEarth Assessment?\n",
      "\n",
      "HackerEarth provides you with industry-leading features which are as follows:\n",
      "\n",
      "---\n",
      "\n",
      "5. Reports and analytics\n",
      "\n",
      "HackerEarth Assessment also offers detailed reports and analytics. These reports give you an insight into each candidate's performance based on various test metrics, including accuracy, speed, and efficiency. You can use this data to identify the strengths and weaknesses of each candidate and make informed hiring decisions.\n",
      "\n",
      "Moreover, HackerEarth Assessment provides smart analytics around usage and recruitment activity to help you make necessary decisions for future recruitment needs. This includes information on the number of tests taken, test completion rates, and candidate performance trends. With this data, you can easily track the effectiveness of your recruitment process and identify areas for improvement.\n",
      "\n",
      "---\n",
      "\n",
      "Advanced proctoring settings for assessments ensure that the tests are conducted in a fair and unbiased manner. HackerEarth Assessment provides best-in-class proctoring mechanisms to prevent cheating and ensure the integrity of the tests. These mechanisms include features such as webcam monitoring, screen recording, and keystroke tracking.\n"
     ]
    }
   ],
   "source": [
    "# messages = [\n",
    "#     (\n",
    "#         \"system\",\n",
    "#         \"You are a helpful assistant that translates English to German. Translate the user sentence.\",\n",
    "#     ),\n",
    "#     (\"human\", \"I love programming.\"),\n",
    "# ]\n",
    "# ai_msg = llm.invoke(messages)\n",
    "# print(ai_msg.content)\n",
    "\n",
    "# testing if context generating is working fine.\n",
    "\n",
    "input_text = \"What kind of services are offered by HackerEarth\"\n",
    "context_text = get_context(input_text)\n",
    "# response = get_completion_from_messages(prompt, input_text, model=llm)\n",
    "print(context_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing well, thank you for asking. Is there something specific you would like to know or discuss regarding HackerEarth Assessment or any of its services? I'd be happy to help answer your questions or provide additional information on the services offered by HackerEarth Assessment. Please let me know if you have any further questions or need more information on the services offered by HackerEarth Assessment.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hi, How are you?\"\n",
    "# prompt_template = ChatPromptTemplate.from_messages(meaku_message)\n",
    "chain = prompt_template | llm\n",
    "response = chain.invoke({\"context_text\": context_text, \"input_text\": input_text})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackerEarth is a leading online technical recruitment platform that offers a wide range of services to its customers. Some of the key services offered by HackerEarth include:\n",
      "\n",
      "  1. Pre-built questions repository: HackerEarth provides a vast repository of pre-built questions in various programming languages, including Python, Java, C++, and more. These pre-built questions are designed to help candidates quickly assess their skills and knowledge against a set of standardized test scenarios.\n",
      "  2. Assess large pool of candidates in 38 different programming languages: HackerEarth provides an advanced platform for assessing large pools of candidates in 38 different programming languages, including Python, Java, C++, and more. This platform allows you to quickly assess the skills and knowledge of each candidate against a set of standardized test scenarios.\n",
      "  3. Versatile platform: HackerEarth provides a versatile platform that enables you to quickly assess the skills and knowledge of each candidate against a set of standardized test scenarios. This platform allows you to quickly assess the skills and knowledge of each candidate against a set of standardized test scenarios, regardless of the programming language used by the candidate.\n",
      "  4. Advanced proctoring settings for assessments: HackerEarth provides advanced proctoring settings for assessments that enable you to quickly assess the skills and knowledge of each candidate against a set of standardized test scenarios. These settings allow you to quickly assess the skills and knowledge of each candidate against a set of standardized test scenarios, regardless of the programming language used by the candidate.\n",
      "  5. Detailed reports and analytics: HackerEarth provides detailed reports and analytics that enable you to quickly assess the skills and knowledge of each candidate against a set of standardized test scenarios. These reports and analytics provide you with detailed information about the performance of each candidate in each programming language, which enables you to quickly identify the strengths and weaknesses of each candidate in each programming language, regardless of the programming language used by the candidate.\n",
      "  6. Dedicated account manager and product specialist available 24/7: HackerEarth provides a dedicated account manager and product specialist available 24/7 that enable you to quickly assess the skills and knowledge of each candidate against a set of standardized test scenarios. These professionals are responsible for managing the customer relationship, providing technical support, and ensuring that the platform is up-to-date with the latest technologies and best practices. With these dedicated account managers and product specialists available 24/7, you can quickly assess the skills and knowledge of each candidate against a set of standardized test scenarios, without any delays or complications in the assessment process.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What kind of services are offered by HackerEarth\"\n",
    "chain = prompt_template | llm\n",
    "response = chain.invoke({\"context_text\": context_text, \"input_text\": input_text})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pre-built questions repository on HackerEarth is a centralized platform that houses a vast collection of pre-built questions in various programming languages. The repository allows users to search for pre-built questions based on their specific requirements or interests.\n",
      "\n",
      "Here are some key features and benefits of the pre-built questions repository on HackerEarth:\n",
      "\n",
      "1. Comprehensive Collection: The repository contains a wide range of pre-built questions in various programming languages, including but not limited to Python, Java, C++, JavaScript, Ruby, Swift, and more. This comprehensive collection allows users to search for pre-built questions based on their specific requirements or interests.\n",
      "\n",
      "2. Easy Search: The pre-built questions repository on HackerEarth provides an easy search feature that allows users to search for pre-built questions based on keywords or phrases entered by the user. This easy search feature ensures that users can quickly find and access the pre-built questions they are looking for, making it easier for them to complete their assessments efficiently.\n",
      "\n",
      "3. Customizable Search: The pre-built questions repository on HackerEarth provides a customizable search feature that allows users to customize the search criteria based on their specific requirements or interests. This customizable search feature ensures that users can quickly find and access the pre-built questions they are looking for, making it easier for them to complete their assessments efficiently.\n",
      "\n",
      "4. Real-Time Updates: The pre-built questions repository on HackerEarth provides real-time updates of pre-built questions in various programming languages, allowing users to stay up-to-date with the latest pre-built questions available in the repository, ensuring that they can quickly find and access the most relevant and useful pre-built questions for their specific needs and requirements.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Tell me more about pre-built questions repository.\"\n",
    "chain = prompt_template | llm\n",
    "response = chain.invoke({\"context_text\": context_text, \"input_text\": input_text})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divye/Desktop/MeakuChatBot/meaku/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f595b793114dcdb84b36ace9465fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'b17c0e44-6f82-480b-9063-2e696fc25eed': {'versionâ€¦"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divye/Desktop/MeakuChatBot/meaku/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/divye/Desktop/MeakuChatBot/meaku/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "panels = []  # collect display\n",
    "\n",
    "\n",
    "def collect_messages(_):\n",
    "    input_text = inp.value_input\n",
    "    inp.value = \"\"\n",
    "    prompt_template.extend([(\"human\", f\"{input_text}\")])\n",
    "    response = get_completion_from_messages(prompt_template, input_text, model=llm)\n",
    "    prompt_template.extend([(\"system\", f\"{response}\")])\n",
    "    panels.extend(pn.Row(\"Human:\", pn.pane.Markdown(input_text, width=600)))\n",
    "    panels.extend(\n",
    "        pn.Row(\n",
    "            \"System:\",\n",
    "            pn.pane.Markdown(\n",
    "                response, width=600, styles={\"background-color\": \"#F6F6F6\"}\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return pn.Column(*panels)\n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder=\"Enter text hereâ€¦\")\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meaku",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
